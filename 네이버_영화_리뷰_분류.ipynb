{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "네이버 영화 리뷰 분류.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMN6lG+CtGRrJH1tSpXiyr+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jisu1013/DL_starting_with_PyTorch/blob/main/%EB%84%A4%EC%9D%B4%EB%B2%84_%EC%98%81%ED%99%94_%EB%A6%AC%EB%B7%B0_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tECviA5veKKY"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssb2cPkid3RB"
      },
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "from konlpy.tag import Mecab\n",
        "from nltk import FreqDist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI4_xIRxkN29"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI86iRDfkRyr"
      },
      "source": [
        "data = pd.read_table('ratings.txt')\n",
        "data[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3ziByfLkk7A"
      },
      "source": [
        "print('전체 샘플의 수: {}'.format(len(data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-p_K_kRkpaF"
      },
      "source": [
        "sample_data = data[:100] #임의로 100개만 저장"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ_sZezEkwpV"
      },
      "source": [
        "정규 표현식을 통해서 데이터를 정제."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ-H11SVkvq-"
      },
      "source": [
        "sample_data['document'] = sample_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "# 한글과 공백을 제외하고 모두 제거\n",
        "sample_data[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J13it3fzlI5V"
      },
      "source": [
        "토큰화 수행. 우선 불용어를 제거하기 위해서 불용어를 우선 정의한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhLrNkA-lGCN"
      },
      "source": [
        "stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSw8nkO8lVpo"
      },
      "source": [
        "형태소 분석기는 mecab을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1_l5iiBlR9Z"
      },
      "source": [
        "tokenizer = Mecab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA5sAkCqlZvE"
      },
      "source": [
        "tokenized=[]\n",
        "for sentence in sample_data['document']:\n",
        "    temp = tokenizer.morphs(sentence) #토큰화\n",
        "    temp = [word for word in temp if not word in stopwords] #불용어 제거\n",
        "    tokenized.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-25EInwlqja"
      },
      "source": [
        "print(tokenized[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CP_L6dfly9X"
      },
      "source": [
        "단어 집합을 만들어보자. NLTK에서는 빈도수 계산 도구인 FreqDist()를 지원한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAprxDDQlxX0"
      },
      "source": [
        "vocab = FreqDist(np.hstack(tokenized))\n",
        "print('단어 집합의 크기 : {}'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7yxkNJAmBDE"
      },
      "source": [
        "단어를 key로, 단어에 대한 빈도수가 value로 저장되어 있다. vocab에 단어를 입력하면 빈도수를 리턴한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRYH1P_xmAKy"
      },
      "source": [
        "vocab['재밌']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPhAUFttmdE0"
      },
      "source": [
        "'재밌'이란 단어가 총 10번 등장함.\n",
        "most_common()는 상위 빈도수를 가진 주어진 수의 단어만을 리턴. \n",
        "\n",
        "이를 사용하여 등장 빈도수가 높은 단어들을 원하는 개수만큼만 얻을 수 있다. \n",
        "\n",
        "등장 빈도수 상위 500개의 단어만 단어 집합으로 저장해보자 !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM0_Ccj-mRLH"
      },
      "source": [
        "vocab_size = 500\n",
        "# 상위 vocab_size개의 단어만 보존\n",
        "vocab = vocab.most_common(vocab_size)\n",
        "print('단어 집합의 크기 : {}'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RVv1dXXoPJV"
      },
      "source": [
        "### 각 단어에 고유한 정수 부여\n",
        "enumerate()는 순서가 있는 자료형(list, set, tuple, dictionary, string)을 입력으로 받아서 인덱스를 순차적으로 함께 리턴한다는 특징이 있다. 인덱스 0과 1은 다른 용도로 남겨 두고 나머지 단어들은 2부터 501까지 순차적으로 인덱스를 부여."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luSl37TPm9yI"
      },
      "source": [
        "word_to_index = {word[0] : index + 2 for index, word in enumerate(vocab)}\n",
        "word_to_index['pad'] = 1\n",
        "word_to_index['unk'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDqGXktVqm-X"
      },
      "source": [
        "이제 기존의 훈련 데이터에서 각 단어를 고유한 정수로 부여하는 작업을 진행."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfVYdNJtql7C"
      },
      "source": [
        "encoded = []\n",
        "for line in tokenized:\n",
        "    temp = []\n",
        "    for w in line:\n",
        "        try:\n",
        "            temp.append(word_to_index[w])\n",
        "        except KeyError:\n",
        "            temp.append(word_to_index['unk'])\n",
        "    encoded.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeWVqq5OtpGH"
      },
      "source": [
        "print(encoded[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFD_zHr7vkEb"
      },
      "source": [
        "###길이가 다른 문장들을 모두 동일한 길이로 바꿔주는 패딩(padding)\n",
        "\n",
        "앞서 단어 집합에 패딩을 위한 토큰인 'pad'를 추가.\n",
        "패딩 작업은 정해준 길이로 모든 샘플들의 길이를 맞춰주되, 길이가 정해준 길이보다 짧은 샘플들에는 'pad' 토큰을 추가하여 길이를 맞춰주는 작업."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys2q6tgNukVc"
      },
      "source": [
        "max_len = max(len(i) for i in encoded)\n",
        "print('리뷰의 최대길이 : %d' % max_len)\n",
        "print('최소 길이:  %d' % min(len(l) for l in encoded))\n",
        "print('리뷰의 평균 길이 : %f' % (sum(map(len, encoded))/len(encoded)))\n",
        "plt.hist([len(s) for s in encoded], bins=50)\n",
        "plt.xlabel('length of sample')\n",
        "plt.ylabel('number of sample')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgS55RiuwdQA"
      },
      "source": [
        "모든 리뷰의 길이를 63으로 통일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQcfhs7wZ7u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}